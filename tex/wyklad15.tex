\documentclass[../main.tex]{subfiles}
\graphicspath{
    {"../img/"}
    {"img/"}
}

\begin{document}
\begin{pytanie}
Czy kolumny $R(t,t_0)$ są liniowo niezależne $\underset{t,t_0\in [a,b]}{\forall} $?
\end{pytanie}
Wiemy, że $R(t,t_0) = \mathbb{I} = \begin{bmatrix} 1&0&\ldots&0\\ \vdots&1&\ddots&\vdots \\ \vdots&\dots&\ddots&\vdots \\ 0&\dots&\dots&1 \end{bmatrix} $.\\
Chcielibyśmy, żeby $\underset{t,t_0\in[a,b] }{\forall} \det R(t,t_0) \neq 0$.

Przypomnienie z algebry:\\
Z macierzą $\begin{bmatrix} a_{11}&\ldots&a_{1n}\\ \vdots & & \vdots \\a_{n1} &\dots& a_{n} \end{bmatrix} $ możemy związać macierz $D = \begin{bmatrix} D_{11}&\ldots&D_{1n}\\ \vdots &&\vdots \\ D_{n1} & \ldots & D_{nn} \end{bmatrix} $.\\
Zatem $\det A$ uzyskamy mnożąc np. pierwszy wiersz $A$ z pierwszą kolumną $D^T$.\\
Pytanie: Co się stanie, jeśli przemnożymy pierwszy wiersz $A$ przez drugą kolumnę $D^T$?
\begin{przyklad}
    $A = \begin{bmatrix} 1&2\\3&4 \end{bmatrix},\quad D = \begin{bmatrix} 4&-3\\ -2&1 \end{bmatrix},\quad D^T = \begin{bmatrix} 4&-2\\-3&1 \end{bmatrix} $ i wtedy
        \[
            \begin{bmatrix} 1&2\\3&4 \end{bmatrix} \begin{bmatrix} 4&-2\\-3&1 \end{bmatrix} = \begin{bmatrix} -2&0\\0&-2 \end{bmatrix}
    ,\]
            zatem $AD^T = \sum_{i=1}^n D_{ik}a_{si} = \delta_{ks}\det A$
\end{przyklad}
\begin{tw}
    (Liouville)\\
    Jeżeli $R(t,t_0)$ - rezolwenta dla problemu
    \begin{align*}
        &\frac{dx}{dt} = A(x)x(t)\\
        &x(t_0) = x_0
    .\end{align*}
    i $x\in \mathbb{R}^n$, to $w(t) = w(t_0)e^{\int_{t_0}^t tr(A(s))ds}$, gdzie $w(t) = \det R(t,t_0)$ i $w(t)$ nazywamy wrońskianem.\\
\end{tw}
    Uwaga:\\
        Zauważmy, że $w(t)$ nigdy nie będzie równa zero, bo
        \[
            w(t_0) = \det(R(t_0,t_0)) = \det \begin{bmatrix} 1&\ldots&0\\0&\ldots&1 \end{bmatrix} = 1
            \]
            a $\left| \int_{t_0}^t tr A(s)ds \right| < +\infty$ (bo $A(t)\to$ lipszycowalna).\\
        Oznacza to, że kolumny $R(t,t_0)$ są $\underset{t,t_0\in [a,b]}{\forall} $ liniowo niezależne, więc możemy badać bazę rozwiązań złożoną z kolumn $R(t,t_0)$
        \begin{dowod}
            Rezolwenta jest postaci:
            \[
                R(t,t_0) = \begin{bmatrix} u_{11}(t) & u_{12}(t) & \ldots & u_{1n}(t)\\ \vdots \\ u_{n1}(t) & \ldots & \ldots & u_{nn}(t)\end{bmatrix}
            ,\]
            gdzie $u_{ij}(t_0) = \delta_{ij}$.\\
            Wiemy, że $\frac{d R(t,t_0)}{dt} = A(t) R(t,t_0)$.\\
            Obserwacja: policzmy $\det R(t,t_0)$ względem pierwszego wiersza:
            \[
                w(t) = (-1)^{1+1}u_{11}(t) \begin{bmatrix} u_{22} & \ldots & u_{2n} \\ \vdots \\ u_{n2}(t) & \ldots & u_{nn}(t) \end{bmatrix} + (\text{ brak  }u_{11})
            .\]
            Zatem $\frac{\partial w(t)}{\partial u_{11}} = D_{11}$ i ogólnie $\frac{\partial w(t)}{\partial u_{ij}} = D_{ij}$.\\
            Zatem $w(t)$ możemy potraktować jako funkcję od $n\times n$ zmiennych.
            \[
                w(t) = w(u_{11}(t), u_{12}(t), \ldots, u_{nn}(t))
            ,\]
            zatem
            \[
                \frac{\partial w(t)}{\partial t} = \frac{\partial w}{\partial u_{11}} \frac{\partial u_{11}}{\partial t} + \frac{\partial w}{\partial u_{12}} \frac{\partial u_{12}}{\partial t} +\ldots+ \frac{\partial w}{\partial u_{nn}} \frac{\partial u_{nn}}{\partial t}
            .\]
            Skoro $\frac{d R(t,t_0)}{dt} = A(t) R(t,t_0)$ to znaczy, że
            \[
                \frac{\partial u_{ki}}{\partial t} = \sum_{s=1}^n a_{ks}u_{si}
            .\]
            Czyli
            \begin{align*}
                &\frac{d w}{dt} = \sum_{k,i}D_{ki} \sum_s a_{ks}u_{si} = \sum_{k=1}^n \sum_{i=1}^n \sum_{s=1}^n a_{ks} D_{ki}u_{si} =\\
                &= \sum_{k=1}^n\sum_{s=1}^n a_{ks}\delta_{ks}w(t) = \sum_{k=1}^n a_{kk}w(t)\\
            .\end{align*}
            Zatem $\frac{\partial w}{\partial t} = tr(A(t))\cdot  w(t)$. Jak przyłożymy obustronnie całkę to otrzymamy:
            \[
                \int_{t_0}^t \frac{dw}{w} = \int_{t_0}^t tr(A(s))ds \implies -\ln t_0 + \ln w = \int_{t_0}^t tr(A(s))ds \to w(t) = e^{\int_{t_0}^t tr(A(s))ds}e^{\ln \ln t_0}
            .\]
            Czyli
            \[
                w(t) = w(t_0) e^{\int_{t_0}^t tr(A(s))ds}\quad\Box
            \]
        \end{dowod}

        \subsection{Równania liniowe wyższych rzędów (na skróty)}
        Rozważmy równanie:
        \begin{equation}
            \label{eq:linwrz}
            \frac{d^n x}{dt^n} = a_0x(t) + a_1x'(t) + \ldots + a_{n-1}x^{n-1}(t)
        \end{equation}
        (gdzie $a_0,\ldots,a_{n-1}\in \mathbb{R}$ ).\\
        Chcemy znaleźć bazę rozwiązań.\\
        Możemy zapisać  (\ref{eq:linwrz}) jako
         \[
             \frac{d}{dt} \begin{bmatrix} x(t)\\ x'(t) \\ \vdots \\ x^{n-1}(t) \end{bmatrix} = \begin{bmatrix} 0&1&0&\ldots&0
         \\ 0&0&1&\ldots&0
         \\ \vdots &&&&1\\
     a_0 & a_1 & \ldots && a_{n-1}\end{bmatrix}
     \begin{bmatrix} x(t) \\ x'(t) \\ \vdots \\ x^{n-1}(t) \end{bmatrix}
        .\]
        Zatem
        \[
            \begin{bmatrix}  x(t) \\ x'(t) \\ \vdots \\ x^n(t) \end{bmatrix} = \sum_i e^{\lambda_i(t-t_0)} \sum_j \frac{t-t_0}{j}(a-\lambda_i \mathbb{I})^{\ln_i - 1}\underbrace{x_0^i}_{(*)}
        .\]
        Chcemy znaleźć pierwiastki $w(\lambda) = \det(A - \lambda \mathbb{I})$
        \begin{przyklad}
            \[
                \begin{bmatrix} 0&1&0&0\\ 0&0&1&0\\ 0&0&0&1\\ a_0&a_1&a_2&a_3 \end{bmatrix}
            .\]
            \begin{align*}
                \det(A - \lambda \mathbb{I}) &= \det \begin{bmatrix} -\lambda & 1 & 0 & 0\\ 0 &-\lambda&1&0\\ 0&0&-\lambda&1\\ a_0&a_1&a_2&a_3-\lambda \end{bmatrix} = a_0(-1)^{1+4} \begin{vmatrix} 1&0&0\\-\lambda&1&0\\0&-\lambda&1 \end{vmatrix} + \\
                    &+ (-1)^{2+4} a_1 \begin{vmatrix} -\lambda&0&0\\0&1&0\\0&-\lambda&1 \end{vmatrix} + (-1)^{3+4}a_2\begin{vmatrix} -\lambda&1&0\\0&-\lambda&0\\0&0&1 \end{vmatrix} + \\
                    &(-1)^{4+4}(a_3-\lambda)\begin{vmatrix} -\lambda&1&0\\0&-\lambda&1\\0&0&-\lambda \end{vmatrix} = -a_0 \cdot 1 - a_1\lambda - a_2\lambda^2 - a_3\lambda^3 + \lambda^4\\
                &\frac{d^4x}{dt^4} = a_0x + a_1x' + a_2x'' + a_3x''',\quad \lambda^4 = a_0+a_1\lambda+a_2\lambda^2+a_3\lambda^3\\
                \\
                &\ddot{x} + \omega^2 x = te^{t}\\
                &\frac{d}{dt} \begin{bmatrix} x\\x'\\ \vdots \\ x^{n+1} \end{bmatrix} = \begin{bmatrix} . \\ . \\ . \\ . \end{bmatrix}\begin{bmatrix} x\\x^1\\ \vdots \\ x^{n+1} \end{bmatrix} + \begin{bmatrix} 0\\ \vdots \\ b(t) \end{bmatrix}\\
                \\
                &\frac{d^nx}{dt^n} = a_0x + a_1x' + \ldots + a_{n-1}x^{n-1}\\
                &\lambda^n = a_0+a_1\lambda+\ldots+a_{n-1}\lambda^{n-1}
            .\end{align*}
            Połóżmy $x = e^{\lambda t}\to$ skrót mnemotechniczny\\
            \[
            e^{\lambda t}\lambda^n = e^{\lambda t}a_0 + a_1 \lambda e^{\lambda t} + \ldots + a_{n-1}\lambda^{n-1}e^{\lambda t}
            .\]
        \end{przyklad}

        \subsection{Warunek początkowy}
        czy można znaleźć współczynniki $x_0^i$ we wzorze $(*)$ bez konieczności rozkładu warunku brzegowego w bazie wektorów własnych macierzy $A$?
        \begin{przyklad}
            Niech $\ddot{x} + \omega^2 x = 0$ i $x(0) = 0, x'(0) = 1$ i wiemy, że $\lambda^2 + \omega^2 = 0$.\\
            Oznacza to, że $x(t) = A e^{i\omega t} + B e^{-i\omega t}(*)$,
            \begin{align*}
                &\lambda_1 = i\omega, &&n_1 = 1\\
                &\lambda_2 = -i\omega, &&n_2 = 1
            .\end{align*}
            gdzie $A$ i $B$ nieznane, ale wiemy, że $x(0) = 0$ i $x'(0) = 1$ i $x'(t) = Ai\omega e^{i\omega t} - Bi\omega e^{-i\omega t}.$\\
            Czyli
            \begin{align*}
            &Ae^{0}+Be^{-0}= 0 \implies -A = +B\\
            &Ai\omega e^{0}- Bi\omega e^{-0} = 1\\
            &2Ai\omega = 1\\
            &A = \frac{1}{2i\omega}\\
            &B = -\frac{1}{2i\omega}
            .\end{align*}
            Czyli
            \[
                x(t) = \frac{1}{2i\omega}\left( e^{i\omega t}- e^{-i\omega t} \right) = \frac{1}{\omega}\sin(\omega t)
            .\]
        \end{przyklad}
        \begin{pytanie}
            Czy możemy zmienić bazę w równaniu (*)?
        \end{pytanie}
        Odp: Możemy. Na przykład przyjmując $x(t) = A \cos(\omega t) + B \sin(\omega t)$. Wówczas
        \begin{align*}
            &x'(t) = -A\omega \sin(\omega t) + B \omega \cos(\omega t)\\
            &x(0) = A = 0\\
            &x'(0) = B\omega = 1 \to B = \frac{1}{\omega} \implies x(t) = \frac{1}{\omega}\sin(\omega t)
        .\end{align*}
        \begin{pytanie}
            Co robić z niejednorością? (Dla równań wyższych rzędów)
        \end{pytanie}
        \[
            \frac{d}{dt}\vec{x} = A \vec{x} + b, \frac{d}{dt} \vec{x} = A \vec{x}, \vec{x} = R(t,t_0)x_0
        .\]
        \begin{przyklad}
            \[
                \ddot{x} + \omega^2 x = e^t (\Delta)
            .\]
            Wiemy, że rozwiązaniem problemu $\ddot{x} + \omega^2 x = 0$ jest $x(t) = A \cos(\omega t) + B \sin(\omega t)$.\\
            Może uzmiennimy stałe:
            \begin{align*}
                &x(t) = A(t) \cos(\omega t) + B(t) \sin(\omega t)\\
                &\dot{x}(t) = \dot{A}(t) \cos(\omega t) - A t \sin (\omega t) + \dot{B} \sin(\omega t) + B(t) t \cos(\omega t)
            .\end{align*}
            W efekcie dostaniemy równanie drugiego rzędu na $A(t)$ i $B(t)$ :(\\
            Zapiszmy więc równanie $(\Delta)$ w postaci macierzowej.
            \[
                \frac{d}{dt}\begin{bmatrix} x\\x' \end{bmatrix} = \begin{bmatrix} 0&1\\-\omega^2&0 \end{bmatrix} \begin{bmatrix} x\\x' \end{bmatrix} + \begin{bmatrix} 0\\e^t \end{bmatrix} (\Delta\nabla)
            .\]
            Jak wygląda rezolwenta?
            \[
                R(t,t_0) = \begin{bmatrix} u_{11}(t)&u_{12}(t)\\ u_{21}(t) & u_{22}(t) \end{bmatrix} \text{ i } \frac{d}{dt}R(t,t_0) = A R(t,t_0), R(t_0,t_0) = 1
            .\]
            $\left(\begin{bmatrix} x\\x' \end{bmatrix} = R(t,t_0)x_0 \right)$.\\
            Zauważmy, że skoro
            \begin{align*}
                &x(t) = A\cos(\omega t) + B \sin(\omega t)\\
                &x'(t) = A\left( \cos(\omega t) \right)' + B\left( \sin(\omega t) \right)'\\
                &\text{to wtedy } \begin{bmatrix} x(t)\\x'(t) \end{bmatrix} = \begin{bmatrix} \cos(\omega t) & \sin(\omega t)\\ -\omega \sin(\omega t) & \omega \cos(\omega t) \end{bmatrix} \begin{bmatrix} A\\B \end{bmatrix}
            .\end{align*}
            I możemy zbudować macierz
            \[
                \begin{bmatrix} u_{11}&u_{12}\\u'_{11}&u'_{12} \end{bmatrix}
            ,\]
            która od rezolwenty różni się tym, że w $t = t_0$ nie zmienia się w macierz jednostkową.\\
            Uzmienniamy stałe:
            \begin{align*}
                (_{\tilde \tilde} ) \begin{bmatrix} x(t)\\x'(t) \end{bmatrix} = \begin{bmatrix} \cos\omega t & \sin\omega t\\ -\omega \sin\omega t & \omega \cos \omega t \end{bmatrix} \begin{bmatrix} A(t) \\B(t)\end{bmatrix}
            \end{align*}
            i wstawiamy do $(\Delta\nabla)$
            \[
                \frac{d}{dt}\begin{bmatrix} \cos\omega t&\sin\omega t\\ -\omega \sin\omega t & \omega \cos\omega t \end{bmatrix} \begin{bmatrix} A(t)\\B(t) \end{bmatrix} = \begin{bmatrix} \ldots \end{bmatrix} + \begin{bmatrix} 0\\e^t \end{bmatrix}
            .\]
            \begin{align*}
                &\begin{bmatrix} \cos\omega t&\sin\omega t\\ -\omega \sin\omega t& \omega \cos\omega t \end{bmatrix} \begin{bmatrix} \dot{A}(t)\\ \dot{B}(t) \end{bmatrix} + \left( \begin{bmatrix} \cos\omega t & \sin\omega t\\ -\omega \sin\omega t & \omega \cos \omega t \end{bmatrix}  \right)'\begin{bmatrix} A(t)\\B(t) \end{bmatrix} = \\
                &\begin{bmatrix} 0&1\\-\omega^2&0 \end{bmatrix} \cdot (_{\tilde \tilde }) + \begin{bmatrix} 0\\e^t \end{bmatrix} \text{, ale }\\
                &\left( \begin{bmatrix} \cos\omega t&\sin\omega t\\ -\omega \sin\omega t & \omega \cos \omega t \end{bmatrix}  \right)' \begin{bmatrix} A(t)\\B(t) \end{bmatrix} = \begin{bmatrix} -\omega \sin\omega t & \omega \cos\omega t\\ -\omega^2\cos\omega t&-\omega^2\sin\omega t \end{bmatrix} \begin{bmatrix} A(t)\\B(t) \end{bmatrix}\\
                &\begin{bmatrix} 0&1\\-\omega^2&0 \end{bmatrix} \begin{bmatrix} \cos\omega t&\sin\omega t\\ -\omega \sin\omega t & \omega \cos\omega t \end{bmatrix} \begin{bmatrix} A(t)\\B(t) \end{bmatrix} = \begin{bmatrix} -\omega \sin\omega t & \omega \cos\omega t \\ -\omega^2\cos\omega t & -\omega^2 \sin\omega t \end{bmatrix}\begin{bmatrix} A(t)\\B(t) \end{bmatrix}\\
                &\begin{bmatrix} \cos\omega t& \sin\omega t\\ \left( \cos\omega t \right) ' & \left( \sin\omega t \right) '  \end{bmatrix} \begin{bmatrix} A'(t)\\B'(t) \end{bmatrix} = \begin{bmatrix} 0\\e^t \end{bmatrix}
            .\end{align*}
            Czyli mamy:
            \begin{align*}
                &A'(t) \cos\omega t + B'(t) \sin\omega t = 0\\
                &A'(t) \left( \cos\omega t \right) ' + B'(t) \left( \sin\omega t \right) ' = e^t\\
                &x(t) = A \cos\omega t+ B\sin\omega t\\
                &x(t) = A(t) \cos\omega t + B(t) \sin\omega t\\
                &x'(t) = A'(t) \cos\omega t+ B'(t) \sin\omega t + A(t) \left( \cos\omega t \right) ' + B(t)\left( \sin\omega t \right) '
            .\end{align*}
        \end{przyklad}
\end{document}
